{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Exdercise: Transfer learning using MobileNetV3\n",
    "Transfer learning is a powerful technique that leverages pre-trained models and applies them to new tasks. This approach allows us to save time and coputational resources by using the knowledge gained from training no large datasets.\n",
    "\n",
    "This excercise will use MobileNetV3, a convolutional neural network architecture for mobile devices, to train a classifier for the Fashion-MNIST dataset using the PyTorch framework.\n",
    "\n",
    "Fashion-MNIST is a drop-in replacement for MNIST (images of size 28x28 with 10 classes), but instead of digits it containes tiny images of clothes!\n",
    "\n",
    "Task:\n",
    "- Load the Fashion-MNIST dataset using the torchvision package.\n",
    "- Define a PyTorch model using the MobileNetV3 architecture.\n",
    "- Train the model on the Fashion-MNIST dataset.\n",
    "- Evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Step 1: Load the Fashion-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Fashion-MNIST dataset\n",
    "\n",
    "import torch\n",
    "# may require pip install torchvision\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def load_data(batch_size, data_dir=\"data\"):\n",
    "    \"\"\"Load the Fashion_MNIST dataset.\"\"\"\n",
    "    \n",
    "    #Define transfors to normalize the data\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(), #converts PIL image to tensor\n",
    "            transforms.Normalize((0.5,),(0.5,)) # Normalizes the data to between 0 and 1\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Download and load the training data\n",
    "    trainset = datasets.FashionMNIST(\n",
    "        data_dir, download = True, train = True, transform = transform\n",
    "    )\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size= batch_size, shuffle = True\n",
    "    )\n",
    "\n",
    "    # Download and load the test data\n",
    "    testset = datasets.FashionMNIST(\n",
    "        data_dir, download=True, train=False, transform=transform\n",
    "    )\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "trainloader, testloader = load_data(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Sometimes it's useful to create functions that will help us work with the labels when they're more complicated that the hardwritte digits 0-9. Let's write those now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some helper functions to help with the lables\n",
    "def get_class_names():\n",
    "    \"\"\"Return th elist of classes in the Fashion_MNIST dataset.\"\"\"\n",
    "    return[\n",
    "        \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
    "    ]\n",
    "\n",
    "def get_class_name(class_index):\n",
    "    \"\"\"Return the class name for the given index.\"\"\"\n",
    "    return get_class_names()[class_index]\n",
    "\n",
    "def get_class_index_for_name(class_name):\n",
    "    \"\"\"Return the class index for the given name.\"\"\"\n",
    "    return get_class_names().index(class_name)\n",
    "\n",
    "for class_index in range(10):\n",
    "    print(f\"class_index: {class_index}, class_name: {get_class_name(class_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show 10 images from the training set with their labels\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to show an image\n",
    "def show_img(img):\n",
    "    img = img / 2 + 0.4 # unnormalize\n",
    "    npimg = img.numpy() # Convert from tensro to numpy array\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0))) # transpose dimensions to (height, width, channels)\n",
    "\n",
    "images, labels = next(iter(trainloader)) # get the first batch\n",
    "\n",
    "# Show images with labels\n",
    "fig = plt.figure(figsize=(15,4))\n",
    "plot_size = 10\n",
    "\n",
    "for idx in np.arange(plot_size):\n",
    "    ax = fig.add_subplot(2, plot_size // 2, idx + 1, xticks=[], yticks=[])\n",
    "    show_img(images[idx])\n",
    "    ax.set_title(get_class_name(int(labels[idx])))\n",
    "\n",
    "plt.show() # show the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Step 2: Define a PyTorch model using the MobileNetV3 architecture\n",
    "\n",
    "The `torchvision.models.mobilenet_v3_large` class provides access to pretrianed MobileNetV3 model. We can use the mdoel and replace the final layer with a fully-connected layer with 10 outputs, since we have 10 classes. We can then freeze the weights of the convlutional layers and train only the new fully-connected layer.\n",
    "\n",
    "Start with inspecting the original MobileNetV3 (small version) first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained MobileNetV3 and inspect its structure\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load the MobileNetV3 model\n",
    "mobilenet_v3_small = models.mobilenet_v3_small(pretrained=True)\n",
    "print(mobilenet_v3_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Note the `classifier` section of the model\n",
    "(classifier): Sequential(\n",
    "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
    "    (1): Hardswish()\n",
    "    (2): Dropout(p=0.2, inplace=True)\n",
    "    (3): Linear(in_features=1024, **out_features=1000**, bias=True)\n",
    "  )\n",
    "\n",
    "  There are 1000 output features but our dataset does not have that many. We need to get the correct number of output nodes for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch import nn\n",
    "\n",
    "# Define a model class that extends the nn.Module class\n",
    "class MobileNetV3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super (MobileNetV3, self).__init__()\n",
    "\n",
    "        # Load the pre-trained MobileNetV3 (small) architecture\n",
    "        self.model = models.mobilenet_v3_small(pretrained=True)\n",
    "\n",
    "        # Replace the last fully-connected layer with a new one of the right size\n",
    "        self.model.classifier[3] = nn.Linear(1024, 10)\n",
    "\n",
    "        # Freeze all the weights of the network except for the last fully-connected layer\n",
    "        self.freeze()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convert 1x28x28 input tensor to 3x28x28 tensor, to convert it to a color image\n",
    "        x = x.repeat(1,3,1,1)\n",
    "\n",
    "        # Resize the input to 244x244 since MobileNetV3 (Small) expects images of that size\n",
    "        if x.shape[2:] != (244,244):\n",
    "            x = F.interpolate(x, size=(244, 244), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        # Forward pass\n",
    "        return self.model(x)\n",
    "\n",
    "    def freeze(self):\n",
    "        # Freeze all the weights of the network except for the last fully-connected layer\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze the final layer\n",
    "        for param in self.model.classifier[3].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def unfreeze(self):\n",
    "        # Unfreeze all the weights of the network\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "# Create an instance of the MobileNetV3 model\n",
    "model = MobileNetV3()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Step 3: Train the model on the MNIST dataset\n",
    "\n",
    "We can train the model using the standard PyTorch training loop. For the loss function, we'll use CrossEntropyLoss. We also use the Adam optimizer with a learning rate of 0.002. We train the model for 1 epoch to see how th emodel performs after just one pass of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Now choose our device automatically (CPU, GPU, OR MPS) and write the training loop.\n",
    "The MPS backend is for M1/M2/ etc Macs.\n",
    "\n",
    "If you're having trouble running the code locally, you can try using the `cpu` mode manually, ie: `device = torch.device(\"cpu\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device as GPU, MPS, or CPU according to availability\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using devicd: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch training loop\n",
    "model = model.to(device) # Move the model weights to device\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_num, (images, labels) in enumerate(trainloader):\n",
    "        # Move the tensors to the device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero out the optimizer's gradient buffer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass (predictions)\n",
    "        pred_images = model(images)\n",
    "\n",
    "        # Calculate the loss and perform back propagation\n",
    "        loss = loss_fn(pred_images, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss for every 100th iteration\n",
    "        if(batch_num) % 100 ==0:\n",
    "            print(\n",
    "                \"Epoch [{}, {}], Batch [{},{}], Loss: {:.4f}\".format(\n",
    "                    epoch + 1, epochs, batch_num +1, len(trainloader), loss.item()\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Step 4: Evalute the model on the test set\n",
    "\n",
    "We evaluate the model by printing the accuracy and plotting a few examples of correct and incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "loss = 0\n",
    "\n",
    "for images, labels in testloader:\n",
    "    # Move the tensors to the device\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss += loss_fn(outputs, labels)\n",
    "\n",
    "    # torch.max return both max and argmax. We get the argmax here.\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(\n",
    "    \"Test Accuracy of the model on the test images: {} %\".format(100 * correct / total)\n",
    ")\n",
    "print(\"Test Loss of the model on the test images: {}\".format(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few examples of correct and incorrect predictions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get the first batch of images and labels\n",
    "images, labels = next(iter(testloader))\n",
    "\n",
    "# Move the tensors to the configured device\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# Plot the images with labels, at most 10\n",
    "fig = plt.figure(figsize=(15,4))\n",
    "\n",
    "for idx in np.arange(min(10, len(images))):\n",
    "    ax = fig.add_subplot(2, 10 // 2, idx + 1, xticks =[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images.cpu()[idx]))\n",
    "\n",
    "    ax.set_title(\n",
    "        \"{} ({})\".format(get_class_name(predicted[idx]), get_class_name(labels[idx])), color=(\"green\" if predicted[idx] == labels[idx] else \"red\")\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
